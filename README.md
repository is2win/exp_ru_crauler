# Excel Crawler

Краулер для обработки Excel файлов и сохранения данных в SQLite.

## Описание

Программа ищет Excel файлы, содержащие в имени текст "РР_исполнения-ДС", в папке, указанной в файле .env.
Для каждого найденного файла обрабатывает все 4 листа и сохраняет данные в базу данных SQLite.

## Установка

1. Установите зависимости:
```bash
pip install -r requirements.txt
```

2. Настройте файл .env, указав путь к папке с файлами и путь к базе данных:
```
SEARCH_DIR=/path/to/your/folder
DB_PATH=/path/to/database.db
```

Если `DB_PATH` не указан, база данных будет сохранена в файл `database.db` в текущей директории.

## Использование

Запустите скрипт:
```bash
python run.py
```

или

```bash
python crawler.py
```

## Структура базы данных

База данных SQLite содержит 4 таблицы (`sheet_1`, `sheet_2`, `sheet_3`, `sheet_4`), соответствующие листам в Excel-файлах. Каждая таблица имеет следующие столбцы:

- `id` - уникальный идентификатор строки
- `file_name` - имя исходного файла
- `row_hash` - хеш строки для проверки уникальности
- Дополнительные столбцы, соответствующие столбцам в Excel-файлах

Все данные хранятся в текстовом формате для обеспечения совместимости. # exp_ru_crauler
